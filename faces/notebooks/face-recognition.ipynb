{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Using mlrun with OpenCV And PyTorch\n",
    " A complete pipeline of data processing, model training and serving function deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install mlrun and kubeflow pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlrun\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/62/47439e3c58ff8680940002a4c038794443554bb65e9095f7addf2a56605a/mlrun-0.4.3-py3-none-any.whl (116kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 4.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting kfp>=0.1.29 (from mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/e6/ffa83beeb2643cb9e66dedcf179e751d5c0b6340186820ba0e49cd245034/kfp-0.2.2.tar.gz (114kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 49.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp>=3.5.0 (from mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/39/7eb5f98d24904e0f6d3edb505d4aa60e3ef83c0a58d6fe18244a51757247/aiohttp-3.6.2-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 23.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting croniter==0.3.31 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/56/02/94e5b63bb6c287fbda8a5693f15898a2b6f56cbdfaf5a5c1c0109d18d062/croniter-0.3.31-py2.py3-none-any.whl\n",
      "Collecting gevent==1.4.0 (from mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/ca/5b5962361ed832847b6b2f9a2d0452c8c2f29a93baef850bb8ad067c7bf9/gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.5MB 9.0MB/s eta 0:00:011��██████████▉              | 3.1MB 73.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nuclio-sdk>=0.0.3 in /conda/lib/python3.6/site-packages (from mlrun) (0.0.7)\n",
      "Requirement already satisfied: requests>=2.20.1 in /conda/lib/python3.6/site-packages (from mlrun) (2.22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in /conda/lib/python3.6/site-packages (from mlrun) (5.3)\n",
      "Collecting Flask>=1.1.1 (from mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 44.6MB/s a 0:00:01\n",
      "\u001b[?25hCollecting tabulate<=0.8.3,>=0.8.0 (from mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 17.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting gunicorn==19.9.0 (from mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/da/b8dd8deb741bff556db53902d4706774c8e1e67265f69528c14c003644e6/gunicorn-19.9.0-py2.py3-none-any.whl (112kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 52.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting nest-asyncio>=1.0.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/05/a511d3c77850879409ca8a5f73257da50b97c28e030a82cdf8b0d359dedf/nest_asyncio-1.2.3-py3-none-any.whl\n",
      "Collecting nuclio-jupyter>=0.8.0 (from mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/ce/938aa2b9dba3b4850e4fb4089059b1b0151decf3369889327189940a7ebe/nuclio_jupyter-0.8.1-py3-none-any.whl (45kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 33.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /conda/lib/python3.6/site-packages (from mlrun) (7.0)\n",
      "Requirement already satisfied: GitPython>=2.1.0 in /conda/lib/python3.6/site-packages (from mlrun) (3.0.5)\n",
      "Requirement already satisfied: boto3>=1.9 in /conda/lib/python3.6/site-packages (from mlrun) (1.11.13)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /conda/lib/python3.6/site-packages (from mlrun) (0.24.2)\n",
      "Collecting sqlalchemy==1.3.11 (from mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/5c/0e1d7ad0ca52544bb12f9cb8d5cc454af45821c92160ffedd38db0a317f6/SQLAlchemy-1.3.11.tar.gz (6.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.0MB 8.6MB/s eta 0:00:011:00:01�██████▊    | 5.2MB 98.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.25,>=1.15 (from kfp>=0.1.29->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl (118kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 49.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /conda/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun) (1.14.0)\n",
      "Requirement already satisfied: certifi in /conda/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil in /conda/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun) (2.8.1)\n",
      "Collecting google-cloud-storage>=1.13.0 (from kfp>=0.1.29->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/6d/75c2a47af99d15aa8b4de4e66226c128e623f8c9d3e27a8588368ccc38fc/google_cloud_storage-1.25.0-py2.py3-none-any.whl (73kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 42.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting kubernetes<=10.0.0,>=8.0.0 (from kfp>=0.1.29->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/09/365f4ad63f71c698c76edb3e666852b87a751ee4b6d23222b09952557d17/kubernetes-10.0.0-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 22.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting PyJWT>=1.6.4 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cryptography>=2.4.2 in /conda/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun) (2.8)\n",
      "Collecting google-auth>=1.6.1 (from kfp>=0.1.29->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/6d/7aae38a9022f982cf8167775c7fc299f203417b698c27080ce09060bba07/google_auth-1.11.0-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 44.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting requests_toolbelt>=0.8.0 (from kfp>=0.1.29->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 23.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle==1.1.1 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/24/fb/4f92f8c0f40a0d728b4f3d5ec5ff84353e705d8ff5e3e447620ea98b06bd/cloudpickle-1.1.1-py2.py3-none-any.whl\n",
      "Collecting kfp-server-api<=0.1.40,>=0.1.18 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/a8/17b5357858272226ef76aab901846589a56c4a43ac93e66577f84c51e587/kfp-server-api-0.1.40.tar.gz\n",
      "Collecting argo-models==2.2.1a (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/53/a92df7c1c793edf2db99b14e428246e4b49b93499a5c9ed013e0aa2416f6/argo-models-2.2.1a0.tar.gz\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /conda/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun) (3.2.0)\n",
      "Collecting Deprecated (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n",
      "Collecting typing-extensions>=3.6.5; python_version < \"3.7\" (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/92/705fe8aca27678e01bbdd7738173b8e7df0088a2202c80352f664630d638/typing_extensions-3.7.4.1-py3-none-any.whl\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp>=3.5.0->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n",
      "\u001b[K    100% |████████████████████████████████| 256kB 50.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4.0,>=2.0 in /conda/lib/python3.6/site-packages (from aiohttp>=3.5.0->mlrun) (3.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /conda/lib/python3.6/site-packages (from aiohttp>=3.5.0->mlrun) (19.3.0)\n",
      "Collecting idna-ssl>=1.0; python_version < \"3.7\" (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
      "Collecting multidict<5.0,>=4.5 (from aiohttp>=3.5.0->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/5a/d423c846bb839105143d4cd90da19d0f3fc972c51be651f92ac419a20698/multidict-4.7.4-cp36-cp36m-manylinux1_x86_64.whl (147kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 53.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0 (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
      "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\" (from gevent==1.4.0->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 34.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /conda/lib/python3.6/site-packages (from requests>=2.20.1->mlrun) (2.8)\n",
      "Collecting Werkzeug>=0.15 (from Flask>=1.1.1->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/a5/d6f8a6e71f15364d35678a4ec8a0186f980b3bd2545f40ad51dd26a87fb1/Werkzeug-1.0.0-py2.py3-none-any.whl (298kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 34.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting itsdangerous>=0.24 (from Flask>=1.1.1->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /conda/lib/python3.6/site-packages (from Flask>=1.1.1->mlrun) (2.11.1)\n",
      "Requirement already satisfied: ipython>=7.2 in /conda/lib/python3.6/site-packages (from nuclio-jupyter>=0.8.0->mlrun) (7.12.0)\n",
      "Requirement already satisfied: tornado>=5 in /conda/lib/python3.6/site-packages (from nuclio-jupyter>=0.8.0->mlrun) (6.0.3)\n",
      "Requirement already satisfied: jupyterlab>=0.35.4 in /conda/lib/python3.6/site-packages (from nuclio-jupyter>=0.8.0->mlrun) (1.0.2)\n",
      "Requirement already satisfied: nbconvert>=5.4 in /conda/lib/python3.6/site-packages (from nuclio-jupyter>=0.8.0->mlrun) (5.6.1)\n",
      "Requirement already satisfied: notebook>=5.7.2 in /conda/lib/python3.6/site-packages (from nuclio-jupyter>=0.8.0->mlrun) (6.0.3)\n",
      "Requirement already satisfied: gitdb2>=2.0.0 in /conda/lib/python3.6/site-packages (from GitPython>=2.1.0->mlrun) (2.0.6)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /conda/lib/python3.6/site-packages (from boto3>=1.9->mlrun) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.13 in /conda/lib/python3.6/site-packages (from boto3>=1.9->mlrun) (1.14.13)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /conda/lib/python3.6/site-packages (from boto3>=1.9->mlrun) (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /conda/lib/python3.6/site-packages (from pandas>=0.23.0->mlrun) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2011k in /conda/lib/python3.6/site-packages (from pandas>=0.23.0->mlrun) (2019.3)\n",
      "Collecting google-resumable-media<0.6dev,>=0.5.0 (from google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/9e/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098/google_resumable_media-0.5.0-py2.py3-none-any.whl\n",
      "Collecting google-cloud-core<2.0dev,>=1.2.0 (from google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/89/3c/8a7531839028c9690e6d14c650521f3bbaf26e53baaeb2784b8c3eb2fb97/google_cloud_core-1.3.0-py2.py3-none-any.whl\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes<=10.0.0,>=8.0.0->kfp>=0.1.29->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 49.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=21.0.0 in /conda/lib/python3.6/site-packages (from kubernetes<=10.0.0,>=8.0.0->kfp>=0.1.29->mlrun) (45.1.0.post20200127)\n",
      "Collecting requests-oauthlib (from kubernetes<=10.0.0,>=8.0.0->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp>=0.1.29->mlrun) (1.13.2)\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth>=1.6.1->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth>=1.6.1->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.6.1->kfp>=0.1.29->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 48.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp>=0.1.29->mlrun) (1.5.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp>=0.1.29->mlrun) (0.15.7)\n",
      "Collecting wrapt<2,>=1.10 (from Deprecated->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /conda/lib/python3.6/site-packages (from Jinja2>=2.10.1->Flask>=1.1.1->mlrun) (1.1.1)\n",
      "Requirement already satisfied: decorator in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (4.4.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (3.0.3)\n",
      "Requirement already satisfied: pickleshare in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (0.7.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (4.8.0)\n",
      "Requirement already satisfied: pygments in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (2.5.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (0.16.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (4.3.3)\n",
      "Requirement already satisfied: backcall in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (0.1.0)\n",
      "Collecting jupyterlab_server~=1.0.0rc0 (from jupyterlab>=0.35.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/6f/c393779becee76dfd275001fe04832a658febfcbc8f70e7828fcbf2a9c4d/jupyterlab_server-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: jupyter-core in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun) (4.6.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun) (0.8.4)\n",
      "Requirement already satisfied: nbformat>=4.4 in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun) (5.0.4)\n",
      "Requirement already satisfied: testpath in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun) (0.6.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun) (0.3)\n",
      "Requirement already satisfied: bleach in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun) (3.1.0)\n",
      "Requirement already satisfied: Send2Trash in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun) (0.8.3)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun) (5.3.4)\n",
      "Requirement already satisfied: pyzmq>=17 in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun) (18.1.1)\n",
      "Requirement already satisfied: ipython-genutils in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun) (0.2.0)\n",
      "Requirement already satisfied: prometheus-client in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun) (0.7.1)\n",
      "Requirement already satisfied: ipykernel in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun) (5.1.4)\n",
      "Requirement already satisfied: smmap2>=2.0.0 in /conda/lib/python3.6/site-packages (from gitdb2>=2.0.0->GitPython>=2.1.0->mlrun) (2.0.5)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /conda/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.13->boto3>=1.9->mlrun) (0.15.2)\n",
      "Collecting google-api-core<2.0.0dev,>=1.16.0 (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/7e/a523169b0cc9ce62d56e07571db927286a94b1a5f51ac220bd97db825c77/google_api_core-1.16.0-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 25.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes<=10.0.0,>=8.0.0->kfp>=0.1.29->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 53.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.4.2->kfp>=0.1.29->mlrun) (2.19)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth>=1.6.1->kfp>=0.1.29->mlrun)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 46.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /conda/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp>=0.1.29->mlrun) (2.1.0)\n",
      "Requirement already satisfied: wcwidth in /conda/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /conda/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /conda/lib/python3.6/site-packages (from jedi>=0.10->ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (0.6.0)\n",
      "Requirement already satisfied: json5 in /conda/lib/python3.6/site-packages (from jupyterlab_server~=1.0.0rc0->jupyterlab>=0.35.4->nuclio-jupyter>=0.8.0->mlrun) (0.9.0)\n",
      "Requirement already satisfied: webencodings in /conda/lib/python3.6/site-packages (from bleach->nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun) (0.5.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun) (1.51.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun) (3.11.3)\n",
      "Building wheels for collected packages: kfp, tabulate, sqlalchemy, kfp-server-api, argo-models, idna-ssl, wrapt\n",
      "  Running setup.py bdist_wheel for kfp ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/ad/b9/c5/0f80efe045de9277b58f7fb1bb37484eab928462ea841454ea\n",
      "  Running setup.py bdist_wheel for tabulate ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "  Running setup.py bdist_wheel for sqlalchemy ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/a3/67/7d/6c41104a1a08ff1a25e260d3edec3ac19203141d1aaa2f0975\n",
      "  Running setup.py bdist_wheel for kfp-server-api ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/9d/aa/13/9954ed56199c04ed57001e1078f90144d1d2bae69a9d8521f5\n",
      "  Running setup.py bdist_wheel for argo-models ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/bd/5b/6b/20cdc06ddb10caa3a86f5804eb9a90122ae8de0bcf19a468d8\n",
      "  Running setup.py bdist_wheel for idna-ssl ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "Successfully built kfp tabulate sqlalchemy kfp-server-api argo-models idna-ssl wrapt\n",
      "\u001b[31mdistributed 2.10.0 has requirement dask>=2.9.0, but you'll have dask 1.1.5 which is incompatible.\u001b[0m\n",
      "Installing collected packages: urllib3, google-resumable-media, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, google-api-core, google-cloud-core, google-cloud-storage, websocket-client, oauthlib, requests-oauthlib, kubernetes, PyJWT, requests-toolbelt, cloudpickle, kfp-server-api, argo-models, tabulate, wrapt, Deprecated, kfp, typing-extensions, multidict, yarl, idna-ssl, async-timeout, aiohttp, croniter, greenlet, gevent, Werkzeug, itsdangerous, Flask, gunicorn, nest-asyncio, nuclio-jupyter, sqlalchemy, mlrun, jupyterlab-server\n",
      "  Found existing installation: urllib3 1.25.8\n",
      "    Uninstalling urllib3-1.25.8:\n",
      "      Successfully uninstalled urllib3-1.25.8\n",
      "  Found existing installation: cloudpickle 1.2.2\n",
      "    Uninstalling cloudpickle-1.2.2:\n",
      "      Successfully uninstalled cloudpickle-1.2.2\n",
      "  Found existing installation: nuclio-jupyter 0.7.6\n",
      "    Uninstalling nuclio-jupyter-0.7.6:\n",
      "      Successfully uninstalled nuclio-jupyter-0.7.6\n",
      "  Found existing installation: SQLAlchemy 1.2.15\n",
      "    Uninstalling SQLAlchemy-1.2.15:\n",
      "      Successfully uninstalled SQLAlchemy-1.2.15\n",
      "  Found existing installation: jupyterlab-server 1.0.6\n",
      "    Uninstalling jupyterlab-server-1.0.6:\n",
      "      Successfully uninstalled jupyterlab-server-1.0.6\n",
      "Successfully installed Deprecated Flask PyJWT Werkzeug aiohttp argo-models async-timeout cachetools cloudpickle croniter gevent google-api-core google-auth google-cloud-core google-cloud-storage google-resumable-media greenlet gunicorn idna-ssl itsdangerous jupyterlab-server kfp kfp-server-api kubernetes mlrun multidict nest-asyncio nuclio-jupyter oauthlib pyasn1 pyasn1-modules requests-oauthlib requests-toolbelt rsa sqlalchemy tabulate typing-extensions urllib3 websocket-client wrapt yarl\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/mlrun/mlrun.git@development\n",
    "# !pip install kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart jupyter kernel after initial installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies for the code and set config \n",
    "\n",
    "It is possible that after installing dependencies locally, you will need to restart Jupyter kernel to successfully import the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change following magic command to %%nuclio cmd -c if the following packages are already installed locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-build\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/b5/c6ca60421991c22e69b9a950b0d046e06d714f79f7071946ab885c7115fb/scikit_build-0.10.0-py2.py3-none-any.whl (66kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 2.8MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: packaging in /conda/lib/python3.6/site-packages (from scikit-build) (20.1)\n",
      "Requirement already satisfied: setuptools>=28.0.0 in /conda/lib/python3.6/site-packages (from scikit-build) (45.1.0.post20200127)\n",
      "Requirement already satisfied: wheel>=0.29.0 in /conda/lib/python3.6/site-packages (from scikit-build) (0.34.2)\n",
      "Requirement already satisfied: six in /conda/lib/python3.6/site-packages (from packaging->scikit-build) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /conda/lib/python3.6/site-packages (from packaging->scikit-build) (2.4.6)\n",
      "Installing collected packages: scikit-build\n",
      "Successfully installed scikit-build-0.10.0\n",
      "Collecting cmake==3.13.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/c4/e69313ade2a3e992e7178744b0e56bdd8f23e79e15066a68cf490504beed/cmake-3.13.3-cp36-cp36m-manylinux1_x86_64.whl (15.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 15.9MB 3.6MB/s eta 0:00:011�██████████████▋    | 13.7MB 73.6MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: cmake\n",
      "Successfully installed cmake-3.13.3\n",
      "Collecting face_recognition\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/ed/ad9a28042f373d4633fc8b49109b623597d6f193d3bbbef7780a5ee8eef2/face_recognition-1.2.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Click>=6.0 in /conda/lib/python3.6/site-packages (from face_recognition) (7.0)\n",
      "Requirement already satisfied: numpy in /conda/lib/python3.6/site-packages (from face_recognition) (1.18.1)\n",
      "Requirement already satisfied: Pillow in /conda/lib/python3.6/site-packages (from face_recognition) (7.0.0)\n",
      "Collecting dlib>=19.7 (from face_recognition)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/92/05c3b98636661cb80d190a5a777dd94effcc14c0f6893222e5ca81e74fbc/dlib-19.19.0.tar.gz (3.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 13.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 100.2MB 469kB/s  eta 0:00:01|▎                               | 819kB 90.1MB/s eta 0:00:02�█                              | 6.1MB 92.3MB/s eta 0:00:02.7MB 95.1MB/s eta 0:00:010:014MB 96.7MB/s eta 0:00:01��█▎                       | 25.8MB 92.1MB/s eta 0:00:01              | 29.9MB 91.9MB/s eta 0:00:01��█████████                     | 34.1MB 85.7MB/s eta 0:00:01/s eta 0:00:01 | 43.4MB 92.7MB/s eta 0:00:01MB/s eta 0:00:01B/s eta 0:00:01    | 61.2MB 95.7MB/s eta 0:00:01�████████████           | 65.7MB 87.8MB/s eta 0:00:01�███▋         | 70.6MB 102.2MB/s eta 0:00:01��███████████████        | 75.0MB 96.3MB/s eta 0:00:01 103.6MB/s eta 0:00:01�█████████████████████████     | 84.2MB 91.9MB/s eta 0:00:01��██████████▌   | 89.1MB 99.3MB/s eta 0:00:01eta 0:00:01��████████████████████████▍| 98.2MB 97.7MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: dlib, face-recognition-models\n",
      "  Running setup.py bdist_wheel for dlib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/96/ac/11/8aadec62cb4fb5b264a9b1b042caf415de9a75f5e165d79a51\n",
      "  Running setup.py bdist_wheel for face-recognition-models ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
      "Successfully built dlib face-recognition-models\n",
      "Installing collected packages: dlib, face-recognition-models, face-recognition\n",
      "Successfully installed dlib-19.19.0 face-recognition-1.2.3 face-recognition-models-0.3.0\n",
      "Collecting opencv-contrib-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/32/c302e32d1cf59fd4132c3d82e4182ddd61ac4f0e22cebec44eb36d2e0fd3/opencv_contrib_python-4.2.0.32-cp36-cp36m-manylinux1_x86_64.whl (34.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 34.2MB 1.4MB/s eta 0:00:011███████████                 | 16.0MB 84.3MB/s eta 0:00:01 |██████████████████▍             | 19.7MB 89.9MB/s eta 0:00:0123.6MB 98.6MB/s eta 0:00:01��█████████████████████████▎     | 28.0MB 89.4MB/s eta 0:00:01�██▎ | 32.4MB 95.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /conda/lib/python3.6/site-packages (from opencv-contrib-python) (1.18.1)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.2.0.32\n",
      "Collecting imutils\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/94/46dcae8c061e28be31bcaa55c560cb30ee9403c9a4bb2659768ec1b9eb7d/imutils-0.5.3.tar.gz\n",
      "Building wheels for collected packages: imutils\n",
      "  Running setup.py bdist_wheel for imutils ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/16/84/1f/bf88641293cda2c8be81a5c4b8ca973dd9125a6dc3767417fd\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.3\n",
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: scikit-learn in /conda/lib/python3.6/site-packages (from sklearn) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /conda/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /conda/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "Requirement already satisfied: pandas in /conda/lib/python3.6/site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /conda/lib/python3.6/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /conda/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2011k in /conda/lib/python3.6/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.14.0)\n",
      "Collecting joblib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 7.2MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: joblib\n",
      "Successfully installed joblib-0.14.1\n",
      "Requirement already satisfied: v3io_frames in /conda/lib/python3.6/site-packages (0.6.6.post4)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /conda/lib/python3.6/site-packages (from v3io_frames) (0.24.2)\n",
      "Requirement already satisfied: grpcio-tools>=1.26.0 in /conda/lib/python3.6/site-packages (from v3io_frames) (1.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.5.3 in /conda/lib/python3.6/site-packages (from v3io_frames) (1.51.0)\n",
      "Requirement already satisfied: requests>=2.19.1 in /conda/lib/python3.6/site-packages (from v3io_frames) (2.22.0)\n",
      "Requirement already satisfied: pytz>=2011k in /conda/lib/python3.6/site-packages (from pandas>=0.23.4->v3io_frames) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /conda/lib/python3.6/site-packages (from pandas>=0.23.4->v3io_frames) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /conda/lib/python3.6/site-packages (from pandas>=0.23.4->v3io_frames) (2.8.1)\n",
      "Requirement already satisfied: grpcio>=1.27.1 in /conda/lib/python3.6/site-packages (from grpcio-tools>=1.26.0->v3io_frames) (1.27.1)\n",
      "Requirement already satisfied: protobuf>=3.5.0.post1 in /conda/lib/python3.6/site-packages (from grpcio-tools>=1.26.0->v3io_frames) (3.11.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /User/.pythonlibs/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /conda/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /conda/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /conda/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (2019.11.28)\n",
      "Requirement already satisfied: six>=1.5 in /conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.23.4->v3io_frames) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /conda/lib/python3.6/site-packages (from protobuf>=3.5.0.post1->grpcio-tools>=1.26.0->v3io_frames) (45.1.0.post20200127)\n"
     ]
    }
   ],
   "source": [
    "%%nuclio cmd\n",
    "pip install scikit-build\n",
    "pip install cmake==3.13.3\n",
    "pip install face_recognition\n",
    "pip install opencv-contrib-python\n",
    "pip install imutils\n",
    "pip install torch torchvision \n",
    "pip install pandas\n",
    "pip install v3io_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio config spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare global variables and perform necessary imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/User/demos/demos/faces/dataset/'\n",
    "ARTIFACTS_PATH = '/User/demos/demos/faces/artifacts/'\n",
    "MODELS_PATH = '/User/demos/demos/faces/models.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import importlib.util\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "import face_recognition\n",
    "from imutils import paths\n",
    "from pickle import load, dump\n",
    "import cv2\n",
    "from mlrun.artifacts import TableArtifact\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import string\n",
    "import v3io_frames as v3f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and define mlrun functions for the pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "from mlrun import new_function, code_to_function, NewTask, mount_v3io\n",
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(context, cuda=True):\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    context.logger.info(f'Running on device: {device}')\n",
    "    \n",
    "    client = v3f.Client(\"framesd:8081\", container=\"users\")\n",
    "    \n",
    "    if not os.path.exists(DATA_PATH + 'processed'):\n",
    "        os.makedirs(DATA_PATH + 'processed')\n",
    "    \n",
    "    if not os.path.exists(DATA_PATH + 'label_pending'):\n",
    "        os.makedirs(DATA_PATH + 'label_pending')\n",
    "    \n",
    "    # If no train images exist in the predefined path we will train the model on a small dataset of movie actresses\n",
    "    if not os.path.exists(DATA_PATH + 'input'):\n",
    "        os.makedirs(DATA_PATH + 'input')\n",
    "        resp = urlopen('https://iguazio-public.s3.amazonaws.com/roy-actresses/Actresses.zip')\n",
    "        zip_ref = zipfile.ZipFile(BytesIO(resp.read()), 'r')\n",
    "        zip_ref.extractall(DATA_PATH + 'input')\n",
    "        zip_ref.close()\n",
    "    \n",
    "    if os.path.exists(DATA_PATH + 'input/__MACOSX'):\n",
    "        shutil.rmtree(DATA_PATH + 'input/__MACOSX')\n",
    "    \n",
    "    idx_file_path = ARTIFACTS_PATH+\"idx2name.csv\"\n",
    "    if os.path.exists(idx_file_path):\n",
    "        idx2name_df = pd.read_csv(idx_file_path)\n",
    "    else:\n",
    "        idx2name_df = pd.DataFrame(columns=['value', 'name'])\n",
    "    \n",
    "    #creates a mapping of classes(person's names) to target value\n",
    "    new_classes_names = [f for f in os.listdir(DATA_PATH + 'input') if not '.ipynb' in f and f not in idx2name_df['name'].values]\n",
    "    \n",
    "    initial_len = len(idx2name_df)\n",
    "    final_len = len(idx2name_df) + len(new_classes_names)\n",
    "    for i in range(initial_len, final_len):\n",
    "        idx2name_df.loc[i] = {'value': i, 'name': new_classes_names.pop()}\n",
    "    \n",
    "    name2idx = idx2name_df.set_index('name')['value'].to_dict()\n",
    "    \n",
    "    #log name to index mapping into mlrun context\n",
    "    context.log_artifact(TableArtifact('idx2name', df=idx2name_df), target_path='idx2name.csv')\n",
    "    \n",
    "    #generates a list of paths to labeled images \n",
    "    imagePaths = [f for f in paths.list_images(DATA_PATH + 'input') if not '.ipynb' in f]\n",
    "    knownEncodings = []\n",
    "    knownLabels = []\n",
    "    fileNames = []\n",
    "    urls = []\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        print(\"[INFO] processing image {}/{}\".format(i + 1, len(imagePaths)))\n",
    "        #extracts label (person's name) of the image\n",
    "        name = imagePath.split(os.path.sep)[-2]\n",
    "        \n",
    "        #prepares to relocate image after extracting features\n",
    "        file_name = imagePath.split(os.path.sep)[-1]\n",
    "        new_path = DATA_PATH + 'processed/' + file_name\n",
    "        \n",
    "        #converts image format to RGB for comptability with face_recognition library\n",
    "        image = cv2.imread(imagePath)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #detects coordinates of faces bounding boxes\n",
    "        boxes = face_recognition.face_locations(rgb, model='hog')\n",
    "        \n",
    "        #computes embeddings for detected faces\n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        \n",
    "        #this code assumes that a person's folder in the dataset does not contain an image with a face other then his own\n",
    "        for enc in encodings:\n",
    "            file_name = name + '_' + ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))                                                           \n",
    "            knownEncodings.append(enc)\n",
    "            knownLabels.append([name2idx[name]])\n",
    "            fileNames.append(file_name)\n",
    "            urls.append(new_path)\n",
    "        \n",
    "        #move image to processed images directory\n",
    "        shutil.move(imagePath, new_path)\n",
    "        \n",
    "    #saves computed encodings to avoid repeating computations\n",
    "    df_x = pd.DataFrame(knownEncodings, columns=['c' + str(i).zfill(3) for i in range(128)]).reset_index(drop=True)\n",
    "    df_y = pd.DataFrame(knownLabels, columns=['label']).reset_index(drop=True)\n",
    "    df_details = pd.DataFrame([['initial training']*3]*len(df_x), columns=['imgUrl', 'camera', 'time'])\n",
    "    df_details['time'] = [datetime.datetime.utcnow()]*len(df_x)\n",
    "    df_details['imgUrl'] = urls\n",
    "    data_df = pd.concat([df_x, df_y, df_details], axis=1)\n",
    "    data_df['fileName'] = fileNames\n",
    "    \n",
    "    client.write(backend='kv', table='iguazio/demos/demos/faces/artifacts/encodings', dfs=data_df, index_cols=['fileName'])\n",
    "    \n",
    "    with open('encodings_path.txt', 'w+') as f:\n",
    "        f.write('iguazio/demos/demos/faces/artifacts/encodings')\n",
    "    context.log_artifact('encodings_path', src_path=f.name, target_path=f.name)\n",
    "    os.remove('encodings_path.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(context, processed_data, model_name='model.bst', cuda=True):\n",
    "    \n",
    "    if cuda:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            context.logger.info(f\"Running on cuda device: {device}\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            context.logger.info(\"Requested running on cuda but no cuda device available.\\nRunning on cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    # prepare data from training\n",
    "    context.logger.info('Client')\n",
    "    client = v3f.Client('framesd:8081', container=\"users\")\n",
    "    with open(processed_data.url, 'r') as f:                      \n",
    "        t = f.read()\n",
    "        \n",
    "    data_df = client.read(backend=\"kv\", table=t, reset_index=False, filter='label != -1')\n",
    "    X = data_df[['c'+str(i).zfill(3) for i in range(128)]].values\n",
    "    y = data_df['label'].values\n",
    "    \n",
    "    n_classes = len(set(y))\n",
    "    \n",
    "    X = torch.as_tensor(X, device=device)\n",
    "    y = torch.tensor(y, device=device).reshape(-1, 1)\n",
    "    \n",
    "    input_dim = 128\n",
    "    hidden_dim = 64\n",
    "    output_dim = n_classes\n",
    "    \n",
    "    spec = importlib.util.spec_from_file_location('models', MODELS_PATH)\n",
    "    models = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(models)\n",
    "    \n",
    "    model = models.FeedForwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "    model.to(device)\n",
    "    model = model.double()\n",
    "    \n",
    "    # define loss and optimizer for the task\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate = 0.05\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    # train the network\n",
    "    n_iters = X.size(0) * 5\n",
    "    for i in range(n_iters):\n",
    "        r = random.randint(0, X.size(0) - 1)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X[r]).reshape(1, -1)\n",
    "        loss = criterion(out, y[r])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    context.logger.info('Save model')\n",
    "    #saves and logs model into mlrun context\n",
    "    dump(model._modules, open(model_name, 'wb'))\n",
    "    context.log_artifact('model', src_path=model_name, target_path=model_name, labels={'framework': 'Pytorch-FeedForwardNN'})\n",
    "    os.remove(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_serving_function = code_to_function(name='recognize-faces', \n",
    "                                      filename='./nuclio-face-prediction.ipynb',\n",
    "                                      kind='nuclio')\n",
    "\n",
    "model_serving_function.with_http(workers=2).apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_serving_function = code_to_function(name='video-api-server', \n",
    "                                      filename='./nuclio-api-serving.ipynb',\n",
    "                                      kind='nuclio')\n",
    "\n",
    "api_serving_function.with_http(workers=2).apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pipeline functions locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task = NewTask(handler=encode_images, out_path=ARTIFACTS_PATH)\n",
    "run = new_function().run(task)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2 = NewTask(handler=train, inputs={'processed_data': run.outputs['encodings_path']}, out_path=ARTIFACTS_PATH)\n",
    "train = new_function().run(task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function from notebook and build image\n",
    "supposed to take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = code_to_function('face-recognition', kind='job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn.deploy()\n",
    "fn.with_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fcc7d5f83c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import mlconf\n",
    "mlconf.dbpath = 'http://mlrun-api:8080'\n",
    "fn.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the lines below based on free GPUs. If you wish to utilize a GPU during training process uncomment the first. If you wish to utilize a GPU for prediction uncomment the latter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn.gpus(1)\n",
    "#serving_function.gpus(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='face recognition pipeline',\n",
    "    description='Creates and deploys a face recognition model'\n",
    ")\n",
    "def face_recognition_pipeline(with_cuda=True):\n",
    "    \n",
    "    encode = fn.as_step(name='encode-images', handler='encode_images', out_path=ARTIFACTS_PATH, outputs=['idx2name', 'encodings_path'],\n",
    "                       inputs={'cuda': with_cuda})\n",
    "    \n",
    "    train = fn.as_step(name='train', handler='train', out_path=ARTIFACTS_PATH, outputs=['model'], \n",
    "                               inputs={'processed_data': encode.outputs['encodings_path'], 'cuda': with_cuda})\n",
    "    \n",
    "    deploy_model = model_serving_function.deploy_step(project='default', models={'face_rec_v1': train.outputs['model']})\n",
    "    \n",
    "    deploy_api = api_serving_function.deploy_step(project='default').after(deploy_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(namespace='default-tenant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For debug purposes compile pipeline code\n",
    "kfp.compiler.Compiler().compile(face_recognition_pipeline, 'face_rec.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.app-lab-b-117.iguazio-cd1.com/pipelines//#/experiments/details/4ff031cd-6683-4b68-99a5-42f8d120aacc\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.app-lab-b-117.iguazio-cd1.com/pipelines//#/runs/details/d4fb5178-6da9-4ed4-b03c-121cefecbc60\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arguments = {}\n",
    "run_result = client.create_run_from_pipeline_func(face_recognition_pipeline, arguments=arguments, run_name='face_rec_1', experiment_name='face_rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
