{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Model - Serving Function\n",
    "\n",
    "This notebook demonstrates how to deploy a Tensorflow model using MLRun & Nuclio.\n",
    "\n",
    "**In this notebook you will:**\n",
    "* Write a Tensorflow-Model class to load and predict on the incoming data\n",
    "* Deploy the model as a serverless function\n",
    "* Invoke the serving endpoint with data as:\n",
    "  * URLs to images hosted on S3\n",
    "  * Direct image send\n",
    "  \n",
    "**Steps:**  \n",
    "* [Define Nuclio function](#Define-Nuclio-function)  \n",
    "  * [Install dependencies and set config](#Install-dependencies-and-set-config)  \n",
    "  * [Model serving class](#Model-Serving-Class)  \n",
    "* [Deploy the serving function to the cluster](#Deploy-the-serving-function-to-the-cluster)  \n",
    "* [Define test parameters](#Define-test-parameters)\n",
    "* [Test the deployed function on the cluster](#Test-the-deployed-function-on-the-cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Nuclio Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the magic commands for deploying this jupyter notebook as a nuclio function we must first import nuclio  \n",
    "Since we do not want to import nuclio in the actual function, the comment annotation `nuclio: ignore` is used. This marks the cell for nuclio, telling it to ignore the cell's values when building the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies and set config\n",
    "> Note: Since tensorflow is being pulled from the baseimage it is not directly installed as a build command.\n",
    "If it is not installed on your system please uninstall and install using the line: `pip install tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting kind to 'nuclio:serving'\n",
      "%nuclio: setting 'MODEL_CLASS' environment variable\n",
      "%nuclio: setting spec.build.baseImage to 'mlrun/mlrun'\n"
     ]
    }
   ],
   "source": [
    "%nuclio config kind=\"nuclio:serving\"\n",
    "%nuclio env MODEL_CLASS=TF2Model\n",
    "\n",
    "# tensorflow 2 use the default serving image (or the mlrun/ml-models for a faster build)\n",
    "\n",
    "%nuclio config spec.build.baseImage = \"mlrun/mlrun\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using packages which are not surely installed on our baseimage, or want to verify that a specific version of the package will be installed we use the `%nuclio cmd` annotation.  \n",
    ">`%nuclio cmd` works both locally and during deployment by default, but can be set with `-c` flag to only run the commands while deploying or `-l` to set the variable for the local environment only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install tensorflow>=2.1\n",
    "pip install requests pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from os import environ, path\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "import mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Serving Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the `TFModel` class which we will use to define data handling and prediction of our model.  \n",
    "\n",
    "The class should consist of:\n",
    "* `__init__(name, model_dir)` - Setup the internal parameters\n",
    "* `load(self)` - How to load the model and broadcast it's ready for prediction\n",
    "* `preprocess(self, body)` - How to handle the incoming event, forming the request to an `{'instances': [<samples>]}` dictionary as requested by the protocol\n",
    "* `predict(self, data)` - Receives and `{'instances': [<samples>]}` and returns the model's prediction as a list\n",
    "* `postprocess(self, data)` - Does any additional processing needed on the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFModel(mlrun.runtimes.MLModelServer):\n",
    "    def __init__(self, name: str, model_dir: str):\n",
    "        super().__init__(name, model_dir)\n",
    "\n",
    "        self.IMAGE_WIDTH = int(environ.get('IMAGE_WIDTH', '128'))\n",
    "        self.IMAGE_HEIGHT = int(environ.get('IMAGE_HEIGHT', '128'))\n",
    "        \n",
    "        try:\n",
    "            with open(environ['classes_map'], 'r') as f:\n",
    "                self.classes = json.load(f)\n",
    "        except:\n",
    "            self.classes = None\n",
    "        \n",
    "    def load(self):\n",
    "        model_file, extra_data = self.get_model('.h5')\n",
    "        self.model = load_model(model_file)\n",
    "        \n",
    "    def preprocess(self, body):\n",
    "        try:\n",
    "            output = {'instances': []}\n",
    "            instances = body.get('instances', [])\n",
    "            for byte_image in instances:\n",
    "                img = Image.open(byte_image)\n",
    "                img = img.resize((self.IMAGE_WIDTH, self.IMAGE_HEIGHT))\n",
    "\n",
    "                # Load image\n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                output['instances'].append(x)\n",
    "            \n",
    "            # Format instances list\n",
    "            output['instances'] = [np.vstack(output['instances'])]\n",
    "            return output\n",
    "        except:\n",
    "            raise Exception(f'received: {body}')\n",
    "            \n",
    "\n",
    "    def predict(self, data):\n",
    "        images = data.get('instances', [])\n",
    "\n",
    "        # Predict\n",
    "        predicted_probability = self.model.predict(images)\n",
    "\n",
    "        # return prediction\n",
    "        return predicted_probability\n",
    "        \n",
    "    def postprocess(self, predicted_probability):\n",
    "        predicted_probabilities = np.max(predicted_probability.tolist()[0])\n",
    "        return {'Mask probability': predicted_probabilities}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To let our nuclio builder know that our function code ends at this point we will use the comment annotation `nuclio: end-code`.  \n",
    "\n",
    "Any new cell from now on will be treated as if a `nuclio: ignore` comment was set, and will not be added to the funcion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}