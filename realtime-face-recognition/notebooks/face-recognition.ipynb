{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Using mlrun with OpenCV And PyTorch\n",
    " A complete pipeline of data processing, model training and serving function deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install mlrun and kubeflow pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/mlrun/mlrun.git@development\n",
    "# !pip install kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart jupyter kernel after initial installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies for the code and set config \n",
    "\n",
    "It is possible that after installing dependencies locally, you will need to restart Jupyter kernel to successfully import the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change following magic command to %%nuclio cmd -c if the following packages are already installed locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%nuclio cmd\n",
    "pip install scikit-build\n",
    "pip install cmake==3.13.3\n",
    "pip install face_recognition\n",
    "pip install opencv-contrib-python\n",
    "pip install imutils\n",
    "pip install torch torchvision \n",
    "pip install pandas\n",
    "pip install v3io_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio config spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare global variables and perform necessary imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/User/demos/demos/realtime-face-recognition/dataset/'\n",
    "ARTIFACTS_PATH = '/User/demos/demos/realtime-face-recognition/artifacts/'\n",
    "MODELS_PATH = '/User/demos/demos/realtime-face-recognition/models.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import importlib.util\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "import face_recognition\n",
    "from imutils import paths\n",
    "from pickle import load, dump\n",
    "import cv2\n",
    "from mlrun.artifacts import TableArtifact\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import string\n",
    "import v3io_frames as v3f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and define mlrun functions for the pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "from mlrun import new_function, code_to_function, NewTask, mount_v3io\n",
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(context, cuda=True):\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    context.logger.info(f'Running on device: {device}')\n",
    "    \n",
    "    client = v3f.Client(\"framesd:8081\", container=\"users\")\n",
    "    \n",
    "    if not os.path.exists(DATA_PATH + 'processed'):\n",
    "        os.makedirs(DATA_PATH + 'processed')\n",
    "    \n",
    "    if not os.path.exists(DATA_PATH + 'label_pending'):\n",
    "        os.makedirs(DATA_PATH + 'label_pending')\n",
    "    \n",
    "    # If no train images exist in the predefined path we will train the model on a small dataset of movie actresses\n",
    "    if not os.path.exists(DATA_PATH + 'input'):\n",
    "        os.makedirs(DATA_PATH + 'input')\n",
    "        resp = urlopen('https://iguazio-public.s3.amazonaws.com/roy-actresses/Actresses.zip')\n",
    "        zip_ref = zipfile.ZipFile(BytesIO(resp.read()), 'r')\n",
    "        zip_ref.extractall(DATA_PATH + 'input')\n",
    "        zip_ref.close()\n",
    "    \n",
    "    if os.path.exists(DATA_PATH + 'input/__MACOSX'):\n",
    "        shutil.rmtree(DATA_PATH + 'input/__MACOSX')\n",
    "    \n",
    "    idx_file_path = ARTIFACTS_PATH+\"idx2name.csv\"\n",
    "    if os.path.exists(idx_file_path):\n",
    "        idx2name_df = pd.read_csv(idx_file_path)\n",
    "    else:\n",
    "        idx2name_df = pd.DataFrame(columns=['value', 'name'])\n",
    "    \n",
    "    #creates a mapping of classes(person's names) to target value\n",
    "    new_classes_names = [f for f in os.listdir(DATA_PATH + 'input') if not '.ipynb' in f and f not in idx2name_df['name'].values]\n",
    "    \n",
    "    initial_len = len(idx2name_df)\n",
    "    final_len = len(idx2name_df) + len(new_classes_names)\n",
    "    for i in range(initial_len, final_len):\n",
    "        idx2name_df.loc[i] = {'value': i, 'name': new_classes_names.pop()}\n",
    "    \n",
    "    name2idx = idx2name_df.set_index('name')['value'].to_dict()\n",
    "    \n",
    "    #log name to index mapping into mlrun context\n",
    "    context.log_artifact(TableArtifact('idx2name', df=idx2name_df), target_path='idx2name.csv')\n",
    "    \n",
    "    #generates a list of paths to labeled images \n",
    "    imagePaths = [f for f in paths.list_images(DATA_PATH + 'input') if not '.ipynb' in f]\n",
    "    knownEncodings = []\n",
    "    knownLabels = []\n",
    "    fileNames = []\n",
    "    urls = []\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        print(\"[INFO] processing image {}/{}\".format(i + 1, len(imagePaths)))\n",
    "        #extracts label (person's name) of the image\n",
    "        name = imagePath.split(os.path.sep)[-2]\n",
    "        \n",
    "        #prepares to relocate image after extracting features\n",
    "        file_name = imagePath.split(os.path.sep)[-1]\n",
    "        new_path = DATA_PATH + 'processed/' + file_name\n",
    "        \n",
    "        #converts image format to RGB for comptability with face_recognition library\n",
    "        image = cv2.imread(imagePath)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #detects coordinates of faces bounding boxes\n",
    "        boxes = face_recognition.face_locations(rgb, model='hog')\n",
    "        \n",
    "        #computes embeddings for detected faces\n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        \n",
    "        #this code assumes that a person's folder in the dataset does not contain an image with a face other then his own\n",
    "        for enc in encodings:\n",
    "            file_name = name + '_' + ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))                                                           \n",
    "            knownEncodings.append(enc)\n",
    "            knownLabels.append([name2idx[name]])\n",
    "            fileNames.append(file_name)\n",
    "            urls.append(new_path)\n",
    "        \n",
    "        #move image to processed images directory\n",
    "        shutil.move(imagePath, new_path)\n",
    "        \n",
    "    #saves computed encodings to avoid repeating computations\n",
    "    df_x = pd.DataFrame(knownEncodings, columns=['c' + str(i).zfill(3) for i in range(128)]).reset_index(drop=True)\n",
    "    df_y = pd.DataFrame(knownLabels, columns=['label']).reset_index(drop=True)\n",
    "    df_details = pd.DataFrame([['initial training']*3]*len(df_x), columns=['imgUrl', 'camera', 'time'])\n",
    "    df_details['time'] = [datetime.datetime.utcnow()]*len(df_x)\n",
    "    df_details['imgUrl'] = urls\n",
    "    data_df = pd.concat([df_x, df_y, df_details], axis=1)\n",
    "    data_df['fileName'] = fileNames\n",
    "    \n",
    "    client.write(backend='kv', table='iguazio/demos/demos/realtime-face-recognition/artifacts/encodings', dfs=data_df, index_cols=['fileName'])\n",
    "    \n",
    "    with open('encodings_path.txt', 'w+') as f:\n",
    "        f.write('iguazio/demos/demos/realtime-face-recognition/artifacts/encodings')\n",
    "    context.log_artifact('encodings_path', src_path=f.name, target_path=f.name)\n",
    "    os.remove('encodings_path.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(context, processed_data, model_name='model.bst', cuda=True):\n",
    "    \n",
    "    if cuda:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            context.logger.info(f\"Running on cuda device: {device}\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            context.logger.info(\"Requested running on cuda but no cuda device available.\\nRunning on cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    # prepare data from training\n",
    "    context.logger.info('Client')\n",
    "    client = v3f.Client('framesd:8081', container=\"users\")\n",
    "    with open(processed_data.url, 'r') as f:                      \n",
    "        t = f.read()\n",
    "        \n",
    "    data_df = client.read(backend=\"kv\", table=t, reset_index=False, filter='label != -1')\n",
    "    X = data_df[['c'+str(i).zfill(3) for i in range(128)]].values\n",
    "    y = data_df['label'].values\n",
    "    \n",
    "    n_classes = len(set(y))\n",
    "    \n",
    "    X = torch.as_tensor(X, device=device)\n",
    "    y = torch.tensor(y, device=device).reshape(-1, 1)\n",
    "    \n",
    "    input_dim = 128\n",
    "    hidden_dim = 64\n",
    "    output_dim = n_classes\n",
    "    \n",
    "    spec = importlib.util.spec_from_file_location('models', MODELS_PATH)\n",
    "    models = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(models)\n",
    "    \n",
    "    model = models.FeedForwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "    model.to(device)\n",
    "    model = model.double()\n",
    "    \n",
    "    # define loss and optimizer for the task\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate = 0.05\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    # train the network\n",
    "    n_iters = X.size(0) * 5\n",
    "    for i in range(n_iters):\n",
    "        r = random.randint(0, X.size(0) - 1)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X[r]).reshape(1, -1)\n",
    "        loss = criterion(out, y[r])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    context.logger.info('Save model')\n",
    "    #saves and logs model into mlrun context\n",
    "    dump(model._modules, open(model_name, 'wb'))\n",
    "    context.log_artifact('model', src_path=model_name, target_path=model_name, labels={'framework': 'Pytorch-FeedForwardNN'})\n",
    "    os.remove(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_serving_function = code_to_function(name='recognize-faces', \n",
    "                                      filename='./nuclio-face-prediction.ipynb',\n",
    "                                      kind='nuclio')\n",
    "\n",
    "model_serving_function.with_http(workers=2).apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_serving_function = code_to_function(name='video-api-server', \n",
    "                                      filename='./nuclio-api-serving.ipynb',\n",
    "                                      kind='nuclio')\n",
    "\n",
    "api_serving_function.with_http(workers=2).apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pipeline functions locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task = NewTask(handler=encode_images, out_path=ARTIFACTS_PATH)\n",
    "run = new_function().run(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2 = NewTask(handler=train, inputs={'processed_data': run.outputs['encodings_path']}, out_path=ARTIFACTS_PATH)\n",
    "train = new_function().run(task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function from notebook and build image\n",
    "supposed to take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = code_to_function('face-recognition', kind='job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn.deploy()\n",
    "fn.with_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mlconf\n",
    "mlconf.dbpath = 'http://mlrun-api:8080'\n",
    "fn.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the lines below based on free GPUs. If you wish to utilize a GPU during training process uncomment the first. If you wish to utilize a GPU for prediction uncomment the latter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn.gpus(1)\n",
    "#serving_function.gpus(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='face recognition pipeline',\n",
    "    description='Creates and deploys a face recognition model'\n",
    ")\n",
    "def face_recognition_pipeline(with_cuda=True):\n",
    "    \n",
    "    encode = fn.as_step(name='encode-images', handler='encode_images', out_path=ARTIFACTS_PATH, outputs=['idx2name', 'encodings_path'],\n",
    "                       inputs={'cuda': with_cuda})\n",
    "    \n",
    "    train = fn.as_step(name='train', handler='train', out_path=ARTIFACTS_PATH, outputs=['model'], \n",
    "                               inputs={'processed_data': encode.outputs['encodings_path'], 'cuda': with_cuda})\n",
    "    \n",
    "    deploy_model = model_serving_function.deploy_step(project='default', models={'face_rec_v1': train.outputs['model']})\n",
    "    \n",
    "    deploy_api = api_serving_function.deploy_step(project='default').after(deploy_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(namespace='default-tenant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For debug purposes compile pipeline code\n",
    "kfp.compiler.Compiler().compile(face_recognition_pipeline, 'face_rec.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "run_result = client.create_run_from_pipeline_func(face_recognition_pipeline, arguments=arguments, run_name='face_rec_1', experiment_name='face_rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
